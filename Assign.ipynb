{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1 of the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            name                        address  \\\n",
      "0       John Doe    123 Main St, Cityville, USA   \n",
      "1     Jane Smith    456 Elm St, Townsville, USA   \n",
      "2  Alice Johnson   789 Oak St, Villagetown, USA   \n",
      "3      Bob Brown  987 Pine St, Hamletville, USA   \n",
      "\n",
      "                               mobile_numbers date_of_birth  \n",
      "0                [123-456-7890, 987-654-3210]    1990-05-15  \n",
      "1                              [555-555-5555]    1985-10-25  \n",
      "2  [111-222-3333, 444-555-6666, 777-888-9999]    1978-03-12  \n",
      "3                                          []    1995-12-03  \n"
     ]
    }
   ],
   "source": [
    "with open(\"EmoplyeeDetails.txt\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "df = pd.DataFrame(data[\"people\"])\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2 of the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Within a directory, multiple files are saved daily with identical names but differentiated by the addition \n",
    "of the date and time in CSV format.\n",
    "Write Python code to read all these files which starts with name “Sales_Data” and store their data in a table. \n",
    "The code should only process files that were not read during the last execution.\n",
    "Additionally, include a mechanism to reprocess previously executed files, deleting their records and reloading \n",
    "them when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = r'C:\\Users\\Aviral Tanwar\\Documents\\GitHub\\WNS_Asign\\heooo'\n",
    "\n",
    "def process_files():\n",
    "    files = [file for file in os.listdir(directory) if file.startswith('Sales_Data')]\n",
    "    \n",
    "    new_files = [file for file in files if file not in processed_files]\n",
    "    \n",
    "    for file in new_files:\n",
    "        filepath = os.path.join(directory, file)\n",
    "        data = pd.read_csv(filepath)\n",
    "              \n",
    "        processed_files.append(file)\n",
    "    \n",
    "    reprocess_files = [file for file in processed_files if file not in files]\n",
    "    \n",
    "    for file in reprocess_files:\n",
    "        filepath = os.path.join(directory, file)\n",
    "        data = pd.read_csv(filepath)\n",
    "        \n",
    "        # Remove records related to the file from the table\n",
    "        # Example: df = df[df['filename_column'] != file]\n",
    "        \n",
    "        # Store the updated data from the file in the table\n",
    "        # Example: df = pd.concat([df, data], ignore_index=True)\n",
    "        \n",
    "        # Remove the file from the list of processed files\n",
    "        processed_files.remove(file)\n",
    "    \n",
    "    # Save the list of processed files for the next execution\n",
    "    with open('processed_files.txt', 'w') as f:\n",
    "        for file in processed_files:\n",
    "            f.write(file + '\\n')\n",
    "\n",
    "# Load the list of processed files from the previous execution\n",
    "processed_files = []\n",
    "if os.path.exists('processed_files.txt'):\n",
    "    with open('processed_files.txt', 'r') as f:\n",
    "        processed_files = [line.strip() for line in f]\n",
    "\n",
    "# Process the files\n",
    "process_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to the directory containing Sales_Data files\n",
    "sales_data_dir = pathlib.Path('path/to/sales_data_directory')\n",
    "\n",
    "# Path to the file storing the last processed file's name\n",
    "last_processed_file = pathlib.Path('path/to/last_processed_file.txt')\n",
    "\n",
    "# Check if the last processed file exists, if not, set it to an empty string\n",
    "if last_processed_file.exists():\n",
    "    with open(last_processed_file, 'r') as f:\n",
    "        last_processed_filename = f.read().strip()\n",
    "else:\n",
    "    last_processed_filename = ''\n",
    "\n",
    "# Find all Sales_Data files in the directory that were not read during the last execution\n",
    "sales_data_files = sorted(sales_data_dir.glob('Sales_Data*.csv'))\n",
    "unprocessed_files = [file for file in sales_data_files if file.name > last_processed_filename]\n",
    "\n",
    "# Create an empty list to store the data\n",
    "sales_data = []\n",
    "\n",
    "# Process all unprocessed files\n",
    "for file in unprocessed_files:\n",
    "    print(f'Processing {file}')\n",
    "    df = pd.read_csv(file)\n",
    "    sales_data.extend(df.values.tolist())\n",
    "\n",
    "# Save the last processed file's name\n",
    "with open(last_processed_file, 'w') as f:\n",
    "    f.write(file.name)\n",
    "\n",
    "# Store data in a table\n",
    "sales_data_table = pd.DataFrame(sales_data, columns=['column1', 'column2', 'column3', '...'])\n",
    "\n",
    "# Save the table as a CSV file\n",
    "sales_data_table.to_csv('sales_data_table.csv', index=False)\n",
    "\n",
    "# If needed, add a mechanism to reprocess previously executed files\n",
    "# For example, you can empty the table and re-read all files\n",
    "if input('Do you want to reprocess previously executed files? (y/n) ').lower() == 'y':\n",
    "    sales_data_table.drop(sales_data_table.index, inplace=True)\n",
    "    for file in sales_data_files:\n",
    "        print(f'Processing {file}')\n",
    "        df = pd.read_csv(file)\n",
    "        sales_data.extend(df.values.tolist())\n",
    "    sales_data_table = pd.DataFrame(sales_data, columns=['column1', 'column2', 'column3', '...'])\n",
    "    sales_data_table.to_csv('sales_data_table.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3 of the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting string: Aaha\n"
     ]
    }
   ],
   "source": [
    "input_string = input(\"Enter the str: \")\n",
    "\n",
    "result = \"\"\n",
    "for i in range(len(input_string)):\n",
    "    if i % 2 == 0:\n",
    "        result += input_string[i]\n",
    "\n",
    "print(\"Resulting string:\", result)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
